{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwcLowCaLDEm"
      },
      "outputs": [],
      "source": [
        "# NumPy\n",
        "\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def timer(func): # timer using decorator\n",
        "  def wrapper(*args, **kwargs):\n",
        "    start_time = time.time()\n",
        "    result = func(*args, **kwargs)\n",
        "    end_time = time.time()\n",
        "    computation_time = end_time - start_time\n",
        "    print(f\"Execution time of {func.__name__}: {computation_time} seconds\")\n",
        "    return result\n",
        "  return wrapper"
      ],
      "metadata": {
        "id": "hGAGEpQRLzq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y = w * x + b + epsilon\n",
        "true_b = 1  # 진짜 데이터 만들기\n",
        "true_w = 2\n",
        "N = 100\n",
        "# y = 2x + 1\n",
        "\n",
        "np.random.seed(42)   # 결과를 고정하기 위해 seed를 42번째 난수로 고정\n",
        "x = np.random.rand(N,1)   # 정규분포를 따르는 데이터 N개 -> 정규분포를 따르는 임의의 숫자 100개가 x에 들어감\n",
        "epsilon = 0.1 * np.random.randn(N,1)\n",
        "\n",
        "# y = 2x + 1 + epsilon\n",
        "y = true_b + true_w * x + epsilon"
      ],
      "metadata": {
        "id": "mVkzvlkzL5IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8:2로 데이터 분리\n",
        "idx = np.arange(N)\n",
        "split_idx = int(N * 0.8)       # 80퍼센트를 가져오겠다\n",
        "\n",
        "train_idx = idx[:split_idx]    # 인덱스 나눠주기\n",
        "val_idx = idx[:split_idx:]\n",
        "\n",
        "#Generates train and validation sets\n",
        "x_train, y_train = x[train_idx], y[train_idx]   # 인덱스 분리 했으니 이제 train set 만들기\n",
        "x_val, y_val = x[val_idx], y[val_idx]"
      ],
      "metadata": {
        "id": "GZWZp6HPNASg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@timer  # 위에 정의되어있음\n",
        "def train_model_numpy(lr=0.1, epochs=1000):\n",
        "  #Learing Rate(알파)는 0.1로 / 데이터 1000번 배우겠다.\n",
        "  # Initialization\n",
        "  b = np.random.rand(1)            # b와 w를 임의로 세팅\n",
        "  w = np.random.rand(1)\n",
        "\n",
        "  for epoch in range(epochs):      # 1000번동안 돌리겠다.\n",
        "    # Loss computation\n",
        "    y_hat = b + w * x_train\n",
        "    error = (y_hat - y_train)\n",
        "    mse_loss = np.mean(error ** 2)   # MSEloss : error를 제곱한 것의 평균\n",
        "\n",
        "    # Gradient computation\n",
        "    b_grad = 2 * np.mean(error)            # w0를 미분했기 때문.\n",
        "    w_grad = 2 * np.mean(x_train * error)  # w0 + w1 * x  -> w1에 대해 미분하면 x가 튀어나옴\n",
        "    b = b - lr * b_grad                    # grad 역방향으로 이동하는데, 알파만큼\n",
        "    w = w - lr * w_grad\n",
        "\n",
        "  return w, b\n",
        "  # train model numpy 완성"
      ],
      "metadata": {
        "id": "te4pJ5-1N2Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_numpy()\n",
        "# (array([1.93680706]), array([1.02341385]))\n",
        "# 1000번 돌리면 이렇게 2, 1 에 가까운 값이 나옴.\n",
        "# x자체에 랜덤성이 부여가 됐기 때문에 epsilon 빼도 됨."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2OnxxhySkWR",
        "outputId": "dbd56743-67af-48c1-ed85-b438f9edb1a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time of train_model_numpy: 0.03900337219238281 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.93680706]), array([1.02341385]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch"
      ],
      "metadata": {
        "id": "pZ_zRD-VVIM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CCgfJ2jPVLvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "-M4836e1VNtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tensor ="
      ],
      "metadata": {
        "id": "nX0RrLCBVQDF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}